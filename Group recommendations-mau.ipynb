{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import random as r\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "links = pd.read_csv('ml-latest-small/links.csv')\n",
    "links.head(5)\n",
    "movies = pd.read_csv('ml-latest-small/movies.csv')\n",
    "movies.head(5)\n",
    "tags = pd.read_csv('ml-latest-small/tags.csv')\n",
    "tags.head(5)\n",
    "ratings = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
    "ratings.head(5)\n",
    "#dropping the timestamp column\n",
    "ratings = ratings.drop(['timestamp'], axis=1)\n",
    "#movie and ratings dataset\n",
    "movie_ratings = pd.merge(ratings, movies, on='movieId')\n",
    "movie_ratings.head()\n",
    "#reshaping the data to table based on column values\n",
    "user_ptable= ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "user_ptable.head()\n",
    "#pearson correlation coefficient\n",
    "def pearson_correlation(user_a_ratings,user_b_ratings):\n",
    "    corr,_ = pearsonr(user_a_ratings,user_b_ratings)\n",
    "    return corr\n",
    "\n",
    "def user_collaborative_filtering(target_user,p_table,correlationfunction):\n",
    "    '''\n",
    "    Gets the most similar users and their correlations to the target user\n",
    "    Parameters: int target_user -user id in the dataset\n",
    "                p_table - data as a pivot table\n",
    "                correlationfunction - the correlation function to be used\n",
    "    Return: dict similar_users -dictionary of users who have rated similar movies as the target user\n",
    "    with their ratings.\n",
    "    '''\n",
    "    similar_users = {}\n",
    "    #other users who are not the target user\n",
    "    for user_b in p_table.index:\n",
    "        if user_b != target_user:\n",
    "            # ratings for the target user and user_b\n",
    "            target_user_ratings = p_table.loc[target_user].dropna()\n",
    "            user_b_ratings = p_table.loc[user_b].dropna()\n",
    "\n",
    "            # common rated movies\n",
    "            common_rated_movies = target_user_ratings.index.intersection(user_b_ratings.index)\n",
    "            #filter for at least 2  common rated movies\n",
    "            if len(common_rated_movies) >= 2:\n",
    "                #filter  ratings to include only common rated movies\n",
    "                target_user_ratings = target_user_ratings[common_rated_movies]\n",
    "                user_b_ratings = user_b_ratings[common_rated_movies]\n",
    "                #check if either contains all the same elements as correlation will be 1 regardless of actual rating\n",
    "                if len(set(target_user_ratings)) == 1 or len(set(user_b_ratings)) == 1:\n",
    "                    continue\n",
    "                similar_users[user_b] = correlationfunction(target_user_ratings,user_b_ratings)\n",
    "                    \n",
    "    return similar_users                                                                                                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prediction(user_a,item_p,p_table,similarities):\n",
    "    '''\n",
    "    Calculates the predicted rating of user `user_a` for item `item_p`.\n",
    "    Parameters: int user_a - the index of the target user\n",
    "                int item_p - the index of the unseen movie by target user\n",
    "                p_table - pivot table of data\n",
    "                similarities - the dictionary of correlations between target user\n",
    "                  and other users.\n",
    "    Return: int prediction - rating of user a for item p\n",
    "    '''\n",
    "    user_a_ratings = p_table.loc[user_a]\n",
    "    mean_usera_ratings = user_a_ratings.mean()\n",
    "    unseen_item_ratings = p_table.loc[:, item_p].dropna()\n",
    "\n",
    "    # Get the similarity scores between the target user and other users who have rated the unseen item.\n",
    "    #relevant_similarities = {}\n",
    "    predicted_rating = 0\n",
    "    weighted_difference = 0\n",
    "    similarity_sum = 0\n",
    "    for user_b, similarity in similarities.items():\n",
    "        if user_b != user_a and user_b in unseen_item_ratings.index:\n",
    "            user_b_ratings = p_table.loc[user_b]\n",
    "            mean_userb_ratings = user_b_ratings.mean()\n",
    "            rating_difference = unseen_item_ratings.loc[user_b] - mean_userb_ratings\n",
    "            weighted_difference += (similarity*rating_difference)\n",
    "            similarity_sum += abs(similarity)\n",
    "\n",
    "    if similarity_sum != 0:\n",
    "        # the prediction as the active user's mean plus the weighted rating differences\n",
    "        predicted_rating = mean_usera_ratings + (weighted_difference / similarity_sum)\n",
    "    else:\n",
    "        predicted_rating = mean_usera_ratings\n",
    "\n",
    "    return np.clip(predicted_rating,0.5,5)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recommendations(user, p_table, correlation_function, prediction_function):\n",
    "    similar_users = user_collaborative_filtering(user, p_table, correlation_function)\n",
    "    sorted_similar_users =  sorted(similar_users.items(), key=lambda item: item[1],reverse=True)\n",
    "    #sorted_similar_users = sorted(similar_users.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    top_similar_users = sorted_similar_users[:10]\n",
    "    top_10_similar_users_dict={}\n",
    "    for user,similarity in top_similar_users:\n",
    "        top_10_similar_users_dict[user]=similarity\n",
    "    user_recommendations = {}\n",
    "    for movie in p_table.columns:\n",
    "        if pd.isna(p_table.loc[user, movie]):\n",
    "            user_recommendations[movie] = prediction_function(user, movie, p_table, top_10_similar_users_dict)\n",
    "    return user_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_recommendations(user_recommendations_dict, aggregation_method, top_n = 10):\n",
    "  \n",
    "    movie_ratings = {}\n",
    "    #user_recommendations_list = [user_recommendations]\n",
    "    for user,recommendations in user_recommendations_dict.items():\n",
    "        for movie, rating in recommendations.items():\n",
    "            if movie not in movie_ratings:\n",
    "                movie_ratings[movie] = []\n",
    "            movie_ratings[movie].append(rating)\n",
    "    aggregated_ratings = {}   \n",
    "    if aggregation_method == 'average':\n",
    "        aggregated_ratings = {movie: np.mean(ratings) for movie, ratings in movie_ratings.items()}\n",
    "\n",
    "    elif aggregation_method == 'least misery':\n",
    "        aggregated_ratings = {movie: np.min(ratings) for movie, ratings in movie_ratings.items()}\n",
    "        \n",
    "    #group recommendations\n",
    "    sorted_group_recommendations = sorted(aggregated_ratings.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_group_recommendations = sorted_group_recommendations[:top_n]\n",
    "\n",
    "    return top_group_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_users = np.random.choice(user_ptable.index, size=3, replace=False)\n",
    "user_recommendations_dict = {}\n",
    "for user in group_users:\n",
    "    user_recommendations_dict [user] = get_user_recommendations(user, user_ptable, pearson_correlation, user_prediction)\n",
    "\n",
    "average_ratings = group_recommendations(user_recommendations_dict,'average')\n",
    "least_misery_ratings = group_recommendations(user_recommendations_dict,'least misery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data, movies_df):\n",
    "    # Assuming movies_df is your DataFrame containing movie information\n",
    "    movie_titles_dict = movies_df.set_index('movieId')['title'].to_dict()\n",
    "\n",
    "    # Extract movie IDs, ratings, and titles from the list of tuples\n",
    "    movie_ids, ratings = zip(*data)\n",
    "    movie_titles = [movie_titles_dict.get(movie_id, 'Unknown') for movie_id in movie_ids]\n",
    "\n",
    "    movie_df = pd.DataFrame({\n",
    "        'Movie ID': movie_ids,\n",
    "        'Title': movie_titles,\n",
    "        'Rating': ratings\n",
    "    })\n",
    "\n",
    "    return movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Movie ID                                              Title    Rating\n",
      "0       318                   Shawshank Redemption, The (1994)  4.902840\n",
      "1       590                          Dances with Wolves (1990)  4.707161\n",
      "2       356                                Forrest Gump (1994)  4.511185\n",
      "3      3578                                   Gladiator (2000)  4.409091\n",
      "4      3996  Crouching Tiger, Hidden Dragon (Wo hu cang lon...  4.397059\n",
      "5      1272                                      Patton (1970)  4.353177\n",
      "6      6502                               28 Days Later (2002)  4.341323\n",
      "7       541                                Blade Runner (1982)  4.339087\n",
      "8      1204                          Lawrence of Arabia (1962)  4.328664\n",
      "9       339                     While You Were Sleeping (1995)  4.327889\n"
     ]
    }
   ],
   "source": [
    "average_recommendations = create_dataframe(average_ratings,movies)\n",
    "print(average_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Movie ID                             Title    Rating\n",
      "0       318  Shawshank Redemption, The (1994)  4.805680\n",
      "1       590         Dances with Wolves (1990)  4.707161\n",
      "2      6502              28 Days Later (2002)  4.258403\n",
      "3       150                  Apollo 13 (1995)  4.188371\n",
      "4       593  Silence of the Lambs, The (1991)  4.173669\n",
      "5      1961                   Rain Man (1988)  4.141944\n",
      "6      1212             Third Man, The (1949)  4.111191\n",
      "7      1214                      Alien (1979)  4.011924\n",
      "8       339    While You Were Sleeping (1995)  3.948617\n",
      "9      3363          American Graffiti (1973)  3.860535\n"
     ]
    }
   ],
   "source": [
    "least_misery_recommendations = create_dataframe(least_misery_ratings,movies)\n",
    "print(least_misery_recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
