{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import random as r\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "links = pd.read_csv('ml-latest-small/links.csv')\n",
    "links.head(5)\n",
    "movies = pd.read_csv('ml-latest-small/movies.csv')\n",
    "movies.head(5)\n",
    "tags = pd.read_csv('ml-latest-small/tags.csv')\n",
    "tags.head(5)\n",
    "ratingss = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
    "ratingss.head(5)\n",
    "#dropping the timestamp column\n",
    "ratings = ratingss.drop(['timestamp'], axis=1)\n",
    "ratings_subsets = [\n",
    "    ratings[:10000], #subset 1\n",
    "    ratings[:20000], #subsets 1-2\n",
    "    ratings[:30000], #subsets 1-3\n",
    "    ratings[:40000], #subsets 1-4\n",
    "    ratings[:50000], #subsets 1-5\n",
    "    ratings[:60000], #subsets 1-6\n",
    "    ratings[:70000], #subsets 1-7\n",
    "    ratings[:80000], #subsets 1-8\n",
    "    ratings[:90000], #subsets 1-9\n",
    "    ratings, #subsets 1-10\n",
    "]\n",
    "#movie and ratings dataset\n",
    "movie_ratings = pd.merge(ratingss, movies, on='movieId')\n",
    "movie_ratings.head()\n",
    "#reshaping the data to table based on column values\n",
    "user_ptable= ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "user_ptable.head()\n",
    "\n",
    "\n",
    "#pearson correlation coefficient\n",
    "def pearson_correlation(user_a_ratings,user_b_ratings):\n",
    "    corr,_ = pearsonr(user_a_ratings,user_b_ratings)\n",
    "    return corr\n",
    "\n",
    "def user_collaborative_filtering(target_user,p_table,correlationfunction):\n",
    "    '''\n",
    "    Gets the most similar users and their correlations to the target user\n",
    "    Parameters: int target_user -user id in the dataset\n",
    "                p_table - data as a pivot table\n",
    "                correlationfunction - the correlation function to be used\n",
    "    Return: dict similar_users -dictionary of users who have rated similar movies as the target user\n",
    "    with their ratings.\n",
    "    '''\n",
    "    similar_users = {}\n",
    "    #other users who are not the target user\n",
    "    for user_b in p_table.index:\n",
    "        if user_b != target_user:\n",
    "            # ratings for the target user and user_b\n",
    "            target_user_ratings = p_table.loc[target_user].dropna()\n",
    "            user_b_ratings = p_table.loc[user_b].dropna()\n",
    "\n",
    "            # common rated movies\n",
    "            common_rated_movies = target_user_ratings.index.intersection(user_b_ratings.index)\n",
    "            #filter for at least 2  common rated movies\n",
    "            if len(common_rated_movies) >= 2:\n",
    "                #filter  ratings to include only common rated movies\n",
    "                target_user_ratings = target_user_ratings[common_rated_movies]\n",
    "                user_b_ratings = user_b_ratings[common_rated_movies]\n",
    "                #check if either contains all the same elements as correlation will be 1 regardless of actual rating\n",
    "                if len(set(target_user_ratings)) == 1 or len(set(user_b_ratings)) == 1:\n",
    "                    continue\n",
    "                similar_users[user_b] = correlationfunction(target_user_ratings,user_b_ratings)\n",
    "                    \n",
    "    return similar_users\n",
    "     \n",
    "def user_prediction(user_a,item_p,p_table,similarities):\n",
    "    '''\n",
    "    Calculates the predicted rating of user `user_a` for item `item_p`.\n",
    "    Parameters: int user_a - the index of the target user\n",
    "                int item_p - the index of the unseen movie by target user\n",
    "                p_table - pivot table of data\n",
    "                similarities - the dictionary of correlations between target user\n",
    "                  and other users.\n",
    "    Return: int prediction - rating of user a for item p\n",
    "    '''\n",
    "    user_a_ratings = p_table.loc[user_a]\n",
    "    mean_usera_ratings = user_a_ratings.mean()\n",
    "    unseen_item_ratings = p_table.loc[:, item_p].dropna()\n",
    "\n",
    "    # Get the similarity scores between the target user and other users who have rated the unseen item.\n",
    "    #relevant_similarities = {}\n",
    "    predicted_rating = 0\n",
    "    weighted_difference = 0\n",
    "    similarity_sum = 0\n",
    "    for user_b, similarity in similarities.items():\n",
    "        if user_b != user_a and user_b in unseen_item_ratings.index:\n",
    "            user_b_ratings = p_table.loc[user_b]\n",
    "            mean_userb_ratings = user_b_ratings.mean()\n",
    "            rating_difference = unseen_item_ratings.loc[user_b] - mean_userb_ratings\n",
    "            weighted_difference += (similarity*rating_difference)\n",
    "            similarity_sum += abs(similarity)\n",
    "\n",
    "    if similarity_sum != 0:\n",
    "        # the prediction as the active user's mean plus the weighted rating differences\n",
    "        predicted_rating = mean_usera_ratings + (weighted_difference / similarity_sum)\n",
    "    else:\n",
    "        predicted_rating = mean_usera_ratings\n",
    "\n",
    "    return np.clip(predicted_rating,0.5,5)\n",
    "\n",
    "def get_user_recommendations(user, p_table, correlation_function, prediction_function,top_n = 10):\n",
    "    '''Function gets the user _recommendations for a particular user using the prediction function\n",
    "    Returns a dictionary of the movie (key) and the predicted rating(value).\n",
    "    p table in this case is the data in the said iteration\n",
    "    '''\n",
    "    similar_users = user_collaborative_filtering(user, p_table, correlation_function)\n",
    "    sorted_similar_users =  sorted(similar_users.items(), key=lambda item: item[1],reverse=True)\n",
    "    #sorted_similar_users = sorted(similar_users.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    top_similar_users = sorted_similar_users[:top_n]\n",
    "    top_10_similar_users_dict={}\n",
    "    for user,similarity in top_similar_users:\n",
    "        top_10_similar_users_dict[user]=similarity\n",
    "    user_recommendations = {}\n",
    "    for movie in p_table.columns:\n",
    "        if pd.isna(p_table.loc[user, movie]):\n",
    "            user_recommendations[movie] = prediction_function(user, movie, p_table, top_10_similar_users_dict)\n",
    "    sorted_user_recommendations =  sorted(user_recommendations.items(), key=lambda item: item[1],reverse=True)\n",
    "    top_10_user_recommendations = sorted_user_recommendations[:top_n]\n",
    "    return user_recommendations\n",
    "   \n",
    "                                                                                                                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def borda_count(user_recommendations_dict):\n",
    "    borda_ratings = {}\n",
    "    for _, recommendations in user_recommendations_dict.items():\n",
    "        rank = len(recommendations)  # Initial rank value\n",
    "        for movie, rating in recommendations.items():\n",
    "            if movie not in borda_ratings:\n",
    "                borda_ratings[movie] = 0\n",
    "            borda_ratings[movie] += rank  # Assigning Borda score based on rank\n",
    "            rank -= 1 \n",
    "    # Normalize Borda count scores to a specific range (0.5 to 5 in this case)\n",
    "    min_score = min(borda_ratings.values())\n",
    "    max_score = max(borda_ratings.values())\n",
    "\n",
    "    for movie, score in borda_ratings.items():\n",
    "        normalized_score = ((score - min_score) / (max_score - min_score)) * (5 - 0.5) + 0.5\n",
    "        borda_ratings[movie] = normalized_score\n",
    "    return borda_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_recommendations(user_recommendations_dict, aggregation_method, top_n = 10):\n",
    "    '''Function calculates the group_recommendation based on the given aggregation method.\n",
    "    The aggregation methods are average and least misery method.\n",
    "    Returns :list(tuple) of the movies and predicted rating based on selected method'''\n",
    "  \n",
    "    movie_ratings = {}\n",
    "    #user_recommendations_list = [user_recommendations]\n",
    "    for user,recommendations in user_recommendations_dict.items():\n",
    "        for movie, rating in recommendations.items():\n",
    "            if movie not in movie_ratings:\n",
    "                movie_ratings[movie] = []\n",
    "            movie_ratings[movie].append(rating)\n",
    "    aggregated_ratings = {}   \n",
    "    if aggregation_method == 'average':\n",
    "        aggregated_ratings = {movie: np.mean(ratings) for movie, ratings in movie_ratings.items()}\n",
    "\n",
    "    elif aggregation_method == 'least misery':\n",
    "        aggregated_ratings = {movie: np.min(ratings) for movie, ratings in movie_ratings.items()}\n",
    "        \n",
    "        \n",
    "    #group recommendations\n",
    "    sorted_group_recommendations = sorted(aggregated_ratings.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_group_recommendations = sorted_group_recommendations[:top_n]\n",
    "\n",
    "    return aggregated_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_group_recommendation(common_recommendations):\n",
    "    '''\n",
    "    parameters : dataframe of  common user recommendations\n",
    "    returns the group recommendations ->pd series\n",
    "    \n",
    "    '''\n",
    "    #Calculating disaggreements\n",
    "    disagreements = 1 - cosine_similarity(common_recommendations.T)\n",
    "    # Create a DataFrame with disagreements\n",
    "    disagreements_df = pd.DataFrame(disagreements, columns=common_recommendations.columns, index=common_recommendations.columns)\n",
    "    weights = 1 - (disagreements_df - disagreements_df.min()) / (disagreements_df.max() - disagreements_df.min())\n",
    "    # Weighted Aggregation for group recommendations\n",
    "    weighted_aggregated_recommendations = common_recommendations.copy()\n",
    "\n",
    "    # multiplying each user's recommendation by their corresponding weight based on disagreements\n",
    "    for user in common_recommendations.columns:\n",
    "        weighted_aggregated_recommendations[user] *= weights.loc[user, user]\n",
    "\n",
    "    # Sum up the weighted recommendations across users to get aggregated recommendations\n",
    "    group_recommendations = weighted_aggregated_recommendations.sum(axis=1)\n",
    "    # normalized aggregated recommendations to range (0 and 5)\n",
    "    min_rating = 0 \n",
    "    max_rating = 5  \n",
    "\n",
    "    normalized_group_recommendations = (\n",
    "        (group_recommendations - group_recommendations.min()) / (group_recommendations.max() - group_recommendations.min())\n",
    "    ) * (max_rating - min_rating) + min_rating\n",
    "    top_10_group_recommendations = normalized_group_recommendations.sort_values(ascending=False).head(10)\n",
    "\n",
    "    return normalized_group_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_predictions(user_ptable,group_users):\n",
    "    user_recommendations_dict = {}\n",
    "    for user in group_users:\n",
    "        user_recommendations_dict [user] = get_user_recommendations(user, user_ptable, pearson_correlation, user_prediction)\n",
    "    #user recommendations dict as a DataFrame\n",
    "    recommendations_df = pd.DataFrame(user_recommendations_dict)\n",
    "    # commonly recommended items to the 3 users\n",
    "    common_recommendations = recommendations_df.dropna(axis=0, how='any')    \n",
    "    average_ratings = group_recommendations(user_recommendations_dict,'average')\n",
    "    least_misery_ratings = group_recommendations(user_recommendations_dict,'least misery')\n",
    "    weighted_agg = weighted_group_recommendation(common_recommendations)\n",
    "    return least_misery_ratings,weighted_agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satisfaction-Optimized Sequential Aggregation Model\n",
    "\n",
    "## Design and Implementation:\n",
    "Sequential Aggregation Model (satisfaction_optimized_sequential_agg_model function):\n",
    "\n",
    "Purpose: Provides sequential recommendations for a group of users, optimizing satisfaction and adapting to evolving preferences.\n",
    "\n",
    "### Parameters:\n",
    "\n",
    "- i: Iteration number (sequential step).\n",
    "\n",
    "- group_users: List of user IDs in the group.\n",
    "\n",
    "- user_ptable: Pivot table of user ratings.\n",
    "\n",
    "- prev_user_satisfactions: Dictionary storing satisfaction scores from previous iterations.\n",
    "\n",
    "- top_n: Number of top recommendations to consider (default is set to 10).\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "- Initialization:For the first iteration (i == 1), it calculates the initial group recommendation using the weighted_group_recommendation function based on the collaborative filtering approach.\n",
    "\n",
    "- Sequential Scores:For subsequent iterations (i > 1), it calculates sequential scores using the compute_scores function, incorporating recommendations from previous iterations.\n",
    "\n",
    "- User Satisfaction:Calculates user satisfaction scores based on either group recommendations (for the first iteration) or sequential scores (for subsequent iterations).\n",
    "\n",
    "- Iteration Update:Updates the satisfaction scores for each user in the prev_user_satisfactions dictionary.\n",
    "\n",
    "- Print Output:Prints the satisfaction scores and recommendations for the current iteration.\n",
    "\n",
    "### Advantages:\n",
    "\n",
    "- Sequential Consideration:Takes into account the sequential nature of group recommendations, considering recommendations and satisfaction scores from previous iterations for a refined experience.\n",
    "\n",
    "- Adaptability with Iterations:Introduces an adaptive factor (alpha) to adjust the importance of previous recommendations, allowing the system to adapt to evolving group preferences.\n",
    "\n",
    "- User-Centric Satisfaction:Incorporates user satisfaction as a key metric, ensuring that recommendations align with individual user preferences for higher overall satisfaction.\n",
    "\n",
    "- Combination of Group and Sequential Approaches:Intelligently combines both group recommendations and sequential scores, starting with collaborative filtering and refining recommendations over iterations.\n",
    "\n",
    "- Flexibility in Recommendation Strategies:Provides flexibility by allowing different aggregation methods for group recommendations, accommodating diverse group preferences.\n",
    "\n",
    "### Theoretical Foundation:\n",
    "\n",
    "- Adaptive Recommendation Adjustment:The method adjusts recommendations based on both predicted preferences and the lowest satisfaction in the group, optimizing for a balance between personalization and group satisfaction.\n",
    "\n",
    "- Sequential Satisfaction Computation:Sequentially computes satisfaction, adapting to evolving preferences and providing a dynamic group recommendation experience.\n",
    "\n",
    "- Combination of Collaborative Filtering and Sequential Scoring:Integrates collaborative filtering for initial group recommendations and sequential scoring for iterative refinement, ensuring a comprehensive and adaptive approach.\n",
    "\n",
    "### Explanation of Method Effectiveness for Sequential Group Recommendations:\n",
    "\n",
    "1. **Sequential Nature Consideration:**\n",
    "   - *Reason:* The method acknowledges that group preferences evolve over time. By considering recommendations and satisfaction scores from previous iterations, it adapts to changing dynamics and provides recommendations aligned with the current state of user preferences.\n",
    "\n",
    "2. **Adaptive Recommendation Adjustment:**\n",
    "   - *Reason:* The introduction of an adaptive factor (`alpha`) allows the system to adjust the influence of previous recommendations. This adaptability optimizes the balance between historical preferences and the most recent ones, ensuring that the system is responsive to shifts in group tastes.\n",
    "\n",
    "3. **User-Centric Satisfaction:**\n",
    "   - *Reason:* The method prioritizes user satisfaction as a key metric for evaluating the effectiveness of recommendations. By focusing on individual satisfaction, it ensures that the group recommendations are tailored to the preferences of each user, contributing to an overall positive group experience.\n",
    "\n",
    "4. **Combination of Collaborative Filtering and Sequential Scoring:**\n",
    "   - *Reason:* The integration of collaborative filtering for initial group recommendations and sequential scoring for iterative refinement creates a comprehensive approach. Collaborative filtering captures the collective preferences of the group, while sequential scoring refines recommendations based on evolving tastes, resulting in a well-rounded solution.\n",
    "\n",
    "5. **Flexibility in Recommendation Strategies:**\n",
    "   - *Reason:* The method offers flexibility by allowing different aggregation methods for group recommendations, such as 'average' or 'least misery.' This adaptability accommodates diverse group preferences and ensures that the system can adjust its strategy based on the nature of the group.\n",
    "\n",
    "6. **Balancing Predicted Preferences and Lowest Satisfaction:**\n",
    "   - *Reason:* The theoretical foundation of balancing recommendations based on both predicted preferences and the lowest satisfaction in the group contributes to a more nuanced and considerate recommendation strategy. It avoids consistently overlooking the preferences of users who might be less satisfied in previous iterations.\n",
    "\n",
    "7. **Holistic Group Satisfaction Approach:**\n",
    "   - *Reason:* By combining sequential considerations, adaptive adjustments, and user-centric satisfaction, the method takes a holistic approach to group satisfaction. It strives to enhance the overall satisfaction of the entire group by catering to individual preferences and adapting to evolving tastes.\n",
    "\n",
    "8. **Dynamic Evolution of Recommendations:**\n",
    "   - *Reason:* The method's design allows for the dynamic evolution of recommendations over sequential iterations. This ensures that the system does not become static and remains responsive to the changing dynamics of the group, providing relevant and timely suggestions.\n",
    "\n",
    "In essence, the proposed method excels in sequential group recommendations by leveraging adaptability, user-centricity, and a combination of collaborative and sequential strategies. It offers a comprehensive and flexible approach that aligns with the dynamic nature of group preferences, ultimately contributing to enhanced group satisfaction over sequential iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (699556516.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\githa\\AppData\\Local\\Temp\\ipykernel_31224\\699556516.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def group_satisfaction():\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def group_satisfaction():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_user_satisfaction(user_ratings_df, group_recommendations):\n",
    "    user_satisfactions = {}\n",
    "\n",
    "    for user_id, user_ratings in user_ratings_df.transpose().iterrows():\n",
    "        user_list_sat = user_ratings.sum()  # total ratings given by the user\n",
    "        group_list_sat = (user_ratings * group_recommendations).sum()  # sum of product of user ratings and group recommendations\n",
    "        \n",
    "        if user_list_sat != 0:  #division by zero\n",
    "            user_satisfactions[user_id] = group_list_sat / user_list_sat\n",
    "        else:\n",
    "            user_satisfactions[user_id] = 0  # Set to 0 if no ratings\n",
    "        \n",
    "    return user_satisfactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(G,user_ptable,alpha,group_users):\n",
    "    '''G set of movies\n",
    "    '''\n",
    "    least_misery_ratings,weighted_agg = get_group_predictions(user_ptable,group_users)\n",
    "    scores = {}\n",
    "    for movie_id in G:\n",
    "        # Find the least misery rating for the current movie\n",
    "        least_score = next((rating for mid, rating in least_misery_ratings if mid == movie_id), 0)\n",
    "        # Find the weighted aggregation score for the current movie\n",
    "        weighted_score = weighted_agg.get(movie_id, 0)\n",
    "\n",
    "        scores = (1 - alpha) * weighted_score + (alpha * least_score)\n",
    "        scores[movie_id] = scores\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_agg_model(i,group_users,user_ptable,top_n = 10):\n",
    "    prev_user_satisfactions = {}\n",
    "    prev_user_satisfactions[0] = {}\n",
    "    user_recommendations_dict = {}#a\n",
    "    G = set()\n",
    "    for user in group_users:\n",
    "        recommendations = get_user_recommendations(user, user_ptable, pearson_correlation, user_prediction)\n",
    "        user_recommendations_dict [user] = recommendations\n",
    "        G.update(recommendations)\n",
    "\n",
    "    #user recommendations dict as a DataFrame\n",
    "    recommendations_df = pd.DataFrame(user_recommendations_dict)\n",
    "    # commonly recommended items to the 3 users\n",
    "    common_recommendations = recommendations_df.dropna(axis=0, how='any')\n",
    "\n",
    "    sequential_scores = {}\n",
    "    if i == 1:\n",
    "        alpha = 0\n",
    "        group_recommendations = weighted_group_recommendation(common_recommendations)#top 10 group recommendations\n",
    "        satisfaction_scores = calculate_user_satisfaction(common_recommendations,group_recommendations)\n",
    "        prev_user_satisfactions[i] = satisfaction_scores\n",
    "    else:\n",
    "        satisfaction_values = prev_user_satisfactions.get(i-1, {})\n",
    "        alpha = max(satisfaction_values.values()) - min(satisfaction_values.values())\n",
    "        \n",
    "        sequential_scores = compute_scores(G,user_ptable,alpha,group_users)\n",
    "        \n",
    "        satisfaction_scores = calculate_user_satisfaction(common_recommendations,sequential_scores)\n",
    "        prev_user_satisfactions[i] = satisfaction_scores\n",
    "        \n",
    "    recommended_movies = group_recommendations.index.tolist()  # List of recommended movie IDs\n",
    "    # Remove recommended movies from user_ptable columns\n",
    "    user_ptable = user_ptable.drop(recommended_movies, axis=1, errors='ignore')\n",
    "\n",
    "    print(f'Iteration {i} Satisfaction Scores: {satisfaction_scores}')\n",
    "    if i == 1:\n",
    "         print(f'Group Recommendations for Iteration {i}: {group_recommendations}')\n",
    "    else:\n",
    "         print(f'Sequential Recommendations for Iteration {i}: {sequential_scores}')\n",
    "\n",
    "    return user_ptable, group_recommendations,sequential_scores,prev_user_satisfactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Satisfaction Scores: {1: 3.4223132037464166, 2: 3.435336012896775, 3: 3.4403983049137956}\n",
      "Group Recommendations for Iteration 1: 2         3.635807\n",
      "3         3.322349\n",
      "4         3.432365\n",
      "5         3.432365\n",
      "6         3.483168\n",
      "            ...   \n",
      "193581    3.432365\n",
      "193583    3.432365\n",
      "193585    3.432365\n",
      "193587    3.432365\n",
      "193609    3.432365\n",
      "Length: 9600, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "group_users = [1,2,3]\n",
    "# First iteration\n",
    "user_ptable, group_recommendations, sequential_scores, prev_user_satisfactions = sequential_agg_model(1, group_users, user_ptable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2959     5.000000\n",
       "48516    2.511031\n",
       "91529    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {},\n",
       " 1: {1: 3.428013807475973, 2: 3.5306512545090936, 3: 3.5508553686439486}}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_user_satisfactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1228415611679754"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2\n",
    "satisfaction_values = prev_user_satisfactions.get(i-1, {})\n",
    "if satisfaction_values:\n",
    "    alpha = max(satisfaction_values.values()) - min(satisfaction_values.values())\n",
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31224\\1051639050.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Second iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0muser_ptable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_recommendations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequential_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_user_satisfactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequential_agg_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_users\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_ptable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31224\\3391821877.py\u001b[0m in \u001b[0;36msequential_agg_model\u001b[1;34m(i, group_users, user_ptable, top_n)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0msatisfaction_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprev_user_satisfactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msatisfaction_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msatisfaction_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0msequential_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser_ptable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgroup_users\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# Second iteration\n",
    "user_ptable, group_recommendations, sequential_scores, prev_user_satisfactions = sequential_agg_model(2, group_users, user_ptable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.951613</td>\n",
       "      <td>4.638581</td>\n",
       "      <td>2.790394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.951613</td>\n",
       "      <td>3.953163</td>\n",
       "      <td>2.790394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.951613</td>\n",
       "      <td>3.798077</td>\n",
       "      <td>3.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.951613</td>\n",
       "      <td>3.798077</td>\n",
       "      <td>3.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.951613</td>\n",
       "      <td>3.365724</td>\n",
       "      <td>3.729486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193581</th>\n",
       "      <td>3.951613</td>\n",
       "      <td>3.798077</td>\n",
       "      <td>3.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193583</th>\n",
       "      <td>3.951613</td>\n",
       "      <td>3.798077</td>\n",
       "      <td>3.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193585</th>\n",
       "      <td>3.951613</td>\n",
       "      <td>3.798077</td>\n",
       "      <td>3.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193587</th>\n",
       "      <td>3.951613</td>\n",
       "      <td>3.798077</td>\n",
       "      <td>3.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193609</th>\n",
       "      <td>3.951613</td>\n",
       "      <td>3.798077</td>\n",
       "      <td>3.186047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9600 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               1         2         3\n",
       "2       3.951613  4.638581  2.790394\n",
       "3       3.951613  3.953163  2.790394\n",
       "4       3.951613  3.798077  3.186047\n",
       "5       3.951613  3.798077  3.186047\n",
       "6       3.951613  3.365724  3.729486\n",
       "...          ...       ...       ...\n",
       "193581  3.951613  3.798077  3.186047\n",
       "193583  3.951613  3.798077  3.186047\n",
       "193585  3.951613  3.798077  3.186047\n",
       "193587  3.951613  3.798077  3.186047\n",
       "193609  3.951613  3.798077  3.186047\n",
       "\n",
       "[9600 rows x 3 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group_users = np.random.choice(user_ptable.index, size=3, replace=False)\n",
    "group_users = [1,2,3]\n",
    "user_recommendations_dict = {}\n",
    "G = set()\n",
    "for user in group_users:\n",
    "    recommendations = get_user_recommendations(user, user_ptable, pearson_correlation, user_prediction)\n",
    "    user_recommendations_dict [user] = recommendations\n",
    "    G.update(recommendations)\n",
    "#user recommendations dict as a DataFrame\n",
    "recommendations_df = pd.DataFrame(user_recommendations_dict)\n",
    "# commonly recommended items to the 3 users\n",
    "common_recommendations = recommendations_df.dropna(axis=0, how='any')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1674, 4.690743338008415),\n",
       " (2028, 4.408039976312374),\n",
       " (47, 4.363581333413423),\n",
       " (58559, 4.356046511627907),\n",
       " (3863, 4.306451612903226),\n",
       " (1198, 4.275758449361477),\n",
       " (2959, 4.111071948281663),\n",
       " (2571, 4.106465656249977),\n",
       " (8368, 4.058493589743589),\n",
       " (4993, 4.033420875171526)]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "least_misery_ratings,weighted_agg = get_group_predictions(user_ptable,group_users)\n",
    "least_misery_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(least_misery_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47      5.000000\n",
       "1198    4.959837\n",
       "3863    4.861231\n",
       "750     4.708015\n",
       "3740    4.708015\n",
       "1129    4.708015\n",
       "2530    4.698955\n",
       "3262    4.698955\n",
       "2116    4.698955\n",
       "4941    4.698955\n",
       "dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.005300486436839696, 2: 0.006554730670875895, 3: 0.007331621190056512}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_recommendation = weighted_group_recommendation(common_recommendations)\n",
    "satisfaction_scores = calculate_user_satisfaction(common_recommendations,group_recommendation)\n",
    "satisfaction_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {1: 0.005300486436839696,\n",
       "  2: 0.006554730670875895,\n",
       "  3: 0.007331621190056512}}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_user_satisfactions = {}\n",
    "prev_user_satisfactions[1] = satisfaction_scores\n",
    "prev_user_satisfactions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
