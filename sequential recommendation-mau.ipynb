{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import random as r\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "links = pd.read_csv('ml-latest-small/links.csv')\n",
    "links.head(5)\n",
    "movies = pd.read_csv('ml-latest-small/movies.csv')\n",
    "movies.head(5)\n",
    "tags = pd.read_csv('ml-latest-small/tags.csv')\n",
    "tags.head(5)\n",
    "ratingss = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
    "ratingss.head(5)\n",
    "#dropping the timestamp column\n",
    "ratings = ratingss.drop(['timestamp'], axis=1)\n",
    "ratings_subsets = [\n",
    "    ratings[:10000], #subset 1\n",
    "    ratings[:20000], #subsets 1-2\n",
    "    ratings[:30000], #subsets 1-3\n",
    "    ratings[:40000], #subsets 1-4\n",
    "    ratings[:50000], #subsets 1-5\n",
    "    ratings[:60000], #subsets 1-6\n",
    "    ratings[:70000], #subsets 1-7\n",
    "    ratings[:80000], #subsets 1-8\n",
    "    ratings[:90000], #subsets 1-9\n",
    "    ratings, #subsets 1-10\n",
    "]\n",
    "#movie and ratings dataset\n",
    "movie_ratings = pd.merge(ratingss, movies, on='movieId')\n",
    "movie_ratings.head()\n",
    "#reshaping the data to table based on column values\n",
    "user_ptable= ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "user_ptable.head()\n",
    "\n",
    "\n",
    "#pearson correlation coefficient\n",
    "def pearson_correlation(user_a_ratings,user_b_ratings):\n",
    "    corr,_ = pearsonr(user_a_ratings,user_b_ratings)\n",
    "    return corr\n",
    "\n",
    "def user_collaborative_filtering(target_user,p_table,correlationfunction):\n",
    "    '''\n",
    "    Gets the most similar users and their correlations to the target user\n",
    "    Parameters: int target_user -user id in the dataset\n",
    "                p_table - data as a pivot table\n",
    "                correlationfunction - the correlation function to be used\n",
    "    Return: dict similar_users -dictionary of users who have rated similar movies as the target user\n",
    "    with their ratings.\n",
    "    '''\n",
    "    similar_users = {}\n",
    "    #other users who are not the target user\n",
    "    for user_b in p_table.index:\n",
    "        if user_b != target_user:\n",
    "            # ratings for the target user and user_b\n",
    "            target_user_ratings = p_table.loc[target_user].dropna()\n",
    "            user_b_ratings = p_table.loc[user_b].dropna()\n",
    "\n",
    "            # common rated movies\n",
    "            common_rated_movies = target_user_ratings.index.intersection(user_b_ratings.index)\n",
    "            #filter for at least 2  common rated movies\n",
    "            if len(common_rated_movies) >= 2:\n",
    "                #filter  ratings to include only common rated movies\n",
    "                target_user_ratings = target_user_ratings[common_rated_movies]\n",
    "                user_b_ratings = user_b_ratings[common_rated_movies]\n",
    "                #check if either contains all the same elements as correlation will be 1 regardless of actual rating\n",
    "                if len(set(target_user_ratings)) == 1 or len(set(user_b_ratings)) == 1:\n",
    "                    continue\n",
    "                similar_users[user_b] = correlationfunction(target_user_ratings,user_b_ratings)\n",
    "                    \n",
    "    return similar_users\n",
    "     \n",
    "def user_prediction(user_a,item_p,p_table,similarities):\n",
    "    '''\n",
    "    Calculates the predicted rating of user `user_a` for item `item_p`.\n",
    "    Parameters: int user_a - the index of the target user\n",
    "                int item_p - the index of the unseen movie by target user\n",
    "                p_table - pivot table of data\n",
    "                similarities - the dictionary of correlations between target user\n",
    "                  and other users.\n",
    "    Return: int prediction - rating of user a for item p\n",
    "    '''\n",
    "    user_a_ratings = p_table.loc[user_a]\n",
    "    mean_usera_ratings = user_a_ratings.mean()\n",
    "    unseen_item_ratings = p_table.loc[:, item_p].dropna()\n",
    "\n",
    "    # Get the similarity scores between the target user and other users who have rated the unseen item.\n",
    "    #relevant_similarities = {}\n",
    "    predicted_rating = 0\n",
    "    weighted_difference = 0\n",
    "    similarity_sum = 0\n",
    "    for user_b, similarity in similarities.items():\n",
    "        if user_b != user_a and user_b in unseen_item_ratings.index:\n",
    "            user_b_ratings = p_table.loc[user_b]\n",
    "            mean_userb_ratings = user_b_ratings.mean()\n",
    "            rating_difference = unseen_item_ratings.loc[user_b] - mean_userb_ratings\n",
    "            weighted_difference += (similarity*rating_difference)\n",
    "            similarity_sum += abs(similarity)\n",
    "\n",
    "    if similarity_sum != 0:\n",
    "        # the prediction as the active user's mean plus the weighted rating differences\n",
    "        predicted_rating = mean_usera_ratings + (weighted_difference / similarity_sum)\n",
    "    else:\n",
    "        predicted_rating = mean_usera_ratings\n",
    "\n",
    "    return np.clip(predicted_rating,0.5,5)\n",
    "\n",
    "def get_user_recommendations(user, p_table, correlation_function, prediction_function,top_n = 10):\n",
    "    '''Function gets the user _recommendations for a particular user using the prediction function\n",
    "    Returns a dictionary of the movie (key) and the predicted rating(value).\n",
    "    p table in this case is the data in the said iteration\n",
    "    '''\n",
    "    similar_users = user_collaborative_filtering(user, p_table, correlation_function)\n",
    "    sorted_similar_users =  sorted(similar_users.items(), key=lambda item: item[1],reverse=True)\n",
    "    #sorted_similar_users = sorted(similar_users.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    top_similar_users = sorted_similar_users[:top_n]\n",
    "    top_10_similar_users_dict={}\n",
    "    for user,similarity in top_similar_users:\n",
    "        top_10_similar_users_dict[user]=similarity\n",
    "    user_recommendations = {}\n",
    "    for movie in p_table.columns:\n",
    "        if pd.isna(p_table.loc[user, movie]):\n",
    "            user_recommendations[movie] = prediction_function(user, movie, p_table, top_10_similar_users_dict)\n",
    "    return user_recommendations\n",
    "   \n",
    "                                                                                                                                                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def borda_count(user_recommendations_dict):\n",
    "    borda_ratings = {}\n",
    "    for _, recommendations in user_recommendations_dict.items():\n",
    "        rank = len(recommendations)  # Initial rank value\n",
    "        for movie, rating in recommendations.items():\n",
    "            if movie not in borda_ratings:\n",
    "                borda_ratings[movie] = 0\n",
    "            borda_ratings[movie] += rank  # Assigning Borda score based on rank\n",
    "            rank -= 1 \n",
    "    # Normalize Borda count scores to a specific range (0.5 to 5 in this case)\n",
    "    min_score = min(borda_ratings.values())\n",
    "    max_score = max(borda_ratings.values())\n",
    "\n",
    "    for movie, score in borda_ratings.items():\n",
    "        normalized_score = ((score - min_score) / (max_score - min_score)) * (5 - 0.5) + 0.5\n",
    "        borda_ratings[movie] = normalized_score\n",
    "    return borda_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_recommendations(user_recommendations_dict, aggregation_method, top_n = 10):\n",
    "    '''Function calculates the group_recommendation based on the given aggregation method.\n",
    "    The aggregation methods are average and least misery method.\n",
    "    Returns :list(tuple) of the movies and predicted rating based on selected method'''\n",
    "  \n",
    "    movie_ratings = {}\n",
    "    #user_recommendations_list = [user_recommendations]\n",
    "    for user,recommendations in user_recommendations_dict.items():\n",
    "        for movie, rating in recommendations.items():\n",
    "            if movie not in movie_ratings:\n",
    "                movie_ratings[movie] = []\n",
    "            movie_ratings[movie].append(rating)\n",
    "    aggregated_ratings = {}   \n",
    "    if aggregation_method == 'average':\n",
    "        aggregated_ratings = {movie: np.mean(ratings) for movie, ratings in movie_ratings.items()}\n",
    "\n",
    "    elif aggregation_method == 'least misery':\n",
    "        aggregated_ratings = {movie: np.min(ratings) for movie, ratings in movie_ratings.items()}\n",
    "        \n",
    "    elif aggregation_method == 'borda':\n",
    "        aggregated_ratings = borda_count(user_recommendations_dict) \n",
    "        \n",
    "    #group recommendations\n",
    "    sorted_group_recommendations = sorted(aggregated_ratings.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_group_recommendations = sorted_group_recommendations[:top_n]\n",
    "\n",
    "    return top_group_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group_users = np.random.choice(user_ptable.index, size=3, replace=False)\n",
    "group_users = [1,2,3]\n",
    "user_recommendations_dict = {}\n",
    "for user in group_users:\n",
    "    user_recommendations_dict [user] = get_user_recommendations(user, user_ptable, pearson_correlation, user_prediction)\n",
    "all_movie_ids = []\n",
    "for user_id, recommendations in user_recommendations_dict.items():\n",
    "    #getting movie ids\n",
    "    all_movie_ids.extend(recommendations.keys())\n",
    "# removing duplicates and converting to list\n",
    "movie_list = list(set(all_movie_ids))#aggregated list from user recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_user_satisfaction(user_id,group_recommendations,user_recommendations):\n",
    "    group_recommendations_ratings = sum(group_recommendations.values())\n",
    "    user_ratings = sum (user_recommendations[movie] for movie in group_recommendations.keys() if movie in user_recommendations) \n",
    "    if user_ratings == 0:\n",
    "        return 0\n",
    "    user_satisfaction = group_recommendations_ratings/user_ratings\n",
    "\n",
    "    return user_satisfaction\n",
    "\n",
    "def user_sat(iteration_data, predictions, rates_by_group, top_k_user_rates, userId):\n",
    "  rates_by_user = rates_by_group[rates_by_group.userId == userId]\n",
    "\n",
    "\n",
    "  group_list_sat = np.sum([user_based_pred(iteration_data, rates_by_user, p) for p in predictions])\n",
    "  user_list_sat = np.sum(top_k_user_rates.rating)\n",
    "\n",
    "  try:\n",
    "    return min([1, group_list_sat / user_list_sat])\n",
    "  except ZeroDivisionError:\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_predictions(user_ptable,group_users):\n",
    "    user_recommendations_dict = {}\n",
    "    for user in group_users:\n",
    "        user_recommendations_dict [user] = get_user_recommendations(user, user_ptable, pearson_correlation, user_prediction)\n",
    "    average_ratings = group_recommendations(user_recommendations_dict,'average')\n",
    "    least_misery_ratings = group_recommendations(user_recommendations_dict,'least misery')\n",
    "    borda_count_ratings = group_recommendations(user_recommendations_dict,'borda')\n",
    "    return average_ratings,least_misery_ratings,borda_count_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_score_dict(avg_ratings,least_misery_ratings, borda_ratings, alpha, beta, gamma):\n",
    "    combined_scores = {}\n",
    "    for movie_id in avg_ratings:\n",
    "        combined_score = alpha * avg_ratings[movie_id] + beta * borda_ratings[movie_id] + gamma * least_misery_ratings[movie_id]\n",
    "        combined_scores[movie_id] = combined_score\n",
    "    return combined_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_score_dict(avg_ratings, least_misery_ratings, borda_ratings, alpha, beta, gamma):\n",
    "    combined_scores = {}\n",
    "    \n",
    "    # Assuming each element in avg_ratings, least_misery_ratings, and borda_ratings is a tuple (movie_id, rating)\n",
    "    for (movie_id, avg_rating), (_, least_misery_rating), (_, borda_rating) in zip(avg_ratings, least_misery_ratings, borda_ratings):\n",
    "        combined_score = alpha * avg_rating + beta * borda_rating + gamma * least_misery_rating\n",
    "        combined_scores[movie_id] = combined_score\n",
    "    \n",
    "    return combined_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_hybrid_agg_model(group_users, iterations = 3, top_n=10):\n",
    "   prev_user_satisfactions = {0: [1 for user in group_users]}\n",
    "   alpha, beta, gamma = 0, 0, 0\n",
    "\n",
    "   for iteration in range(1, iterations + 1):\n",
    "    data = ratings_subsets[iteration - 1]\n",
    "    \n",
    "\n",
    "    recommendations = []\n",
    "\n",
    "    user_preferences = {}\n",
    "    group_ratings = []\n",
    "    for user in group_users:\n",
    "        user_ratings = data[data.userId == user]\n",
    "\n",
    "        group_ratings.append(user_ratings)\n",
    "\n",
    "        user_preferences[user] = user_ratings.sort_values(by=['rating'], ascending=False)[:top_n]\n",
    "\n",
    "    group_ratings = pd.concat(group_ratings)\n",
    "\n",
    "    average_satisfaction = sum(prev_user_satisfactions[iteration - 1]) / len(prev_user_satisfactions[iteration - 1])\n",
    "    variance_satisfaction = np.var(prev_user_satisfactions[iteration - 1])\n",
    "\n",
    "    beta = average_satisfaction / 2 - variance_satisfaction\n",
    "    gamma = average_satisfaction / 2 + average_satisfaction\n",
    "    alpha = 1 - (beta + gamma)\n",
    "\n",
    "    avg_aggregation, least_misery_aggregation, borda_aggregation = get_group_predictions(user_ptable,group_users)\n",
    "    scores = get_combined_score_dict(avg_aggregation, least_misery_aggregation, borda_aggregation ,alpha, beta, gamma)\n",
    "\n",
    "    for movie_id, score in scores.items():\n",
    "    # Include aggregation details accordingly\n",
    "        recommendations.append({\n",
    "            'movieId': movie_id,\n",
    "            'rate': score,\n",
    "            'message': f\"movieId:{movie_id} with rating:{score}, \"\n",
    "        })\n",
    "        \n",
    "\n",
    "    recommendations = sorted(recommendations, key=lambda i: i['rate'], reverse=True)[:top_n]\n",
    "    predictions = [x['movieId'] for x in recommendations]\n",
    "\n",
    "    \n",
    "    print(f\"Top {top_n} Recommended Movies for group:{group_users} in iteration {iteration}\")\n",
    "    for idx, each in enumerate(recommendations):\n",
    "        print(f\"{idx + 1}. {each['message']}\")\n",
    "    prev_user_satisfactions[iteration ] = [user_sat(data, predictions, group_ratings, user_preferences[user], user) for user in group_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Recommended Movies for group:[8, 312, 609] in iteration 1\n",
      "1. movieId:1 with rating:5.0, \n",
      "2. movieId:318 with rating:4.99976743384785, \n",
      "3. movieId:2959 with rating:4.963820581981414, \n",
      "4. movieId:527 with rating:4.599277584315145, \n",
      "5. movieId:1304 with rating:4.523512611375011, \n",
      "6. movieId:3897 with rating:4.479036064545451, \n",
      "7. movieId:2706 with rating:4.241645711166858, \n",
      "8. movieId:1233 with rating:4.139315747152899, \n",
      "9. movieId:4878 with rating:4.135403759920003, \n",
      "10. movieId:1213 with rating:4.129614878659986, \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31224\\1866273978.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgroup_users\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m312\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m609\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequential_hybrid_agg_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_users\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31224\\1338213586.py\u001b[0m in \u001b[0;36msequential_hybrid_agg_model\u001b[1;34m(group_users, iterations, top_n)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mgroup_ratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_ratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0maverage_satisfaction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_user_satisfactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_user_satisfactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mvariance_satisfaction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_user_satisfactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "group_users = [8, 312, 609]\n",
    "s=sequential_hybrid_agg_model(group_users)\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
